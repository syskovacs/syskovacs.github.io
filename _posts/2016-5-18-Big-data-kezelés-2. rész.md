---
layout: post
title: Big data kezelés - 2.rész
---

Egy klaszter tervezése és megszervezése nagy feladat, nagyon sok tényezővel. Első körben fontos a hálózati beállítások és megfelelő sávszélesség biztosítása. A helytelen konfiguráció ezen a téren már a telepítést is ellehetetlenítheti. A DNS és reverse DNS helyes működése atomi fontosságú. A klaszter általában belső hálózaton van és VPN-en keresztül érhető el, ez maximalizálja az elérhető biztonságot, a külső támadások kiszűrhetőek.

A következő lépés a szoftver és hardver elemek kiválasztása. A replikáció miatt a Hadoop 3 különböző helyen tárol minden adatot, így legalább 3 gépen célszerű futtatni, amelyek mindegyike legalább 8-24 GB memóriával rendelkezik. A tárterület tervezése nagyban függ a beérkező kérések számától is, a gépenkénti 1 TB összterület mondható sztenderdnek. A Hadoop verziók jelenleg Unix környezetre érhetőek el, amellett, hogy létezik egy kiadás Windows Server-re is, ám ennek felhasználói tábora elenyésző. A rendszer szempontjából az egyes operációs rendszerek között nincsenek nagy különbségek, így vállalati környezetben általában RedHat-et, míg otthoni felhasználók Ubuntu-t vagy Debian-t használnak. Akár csak a Linux operációs rendszerek világában, a Hadoop-nak is számtalan disztribúciója van, amelyek egy-egy vállalat fejlesztése alatt állnak. Legismertebb a Cloudera és a Hortonworks. Természetesen a Hadoop minden komponense letölthető, telepíthető és konfigurálható, de egy disztribúció használatával ennek időigénye nagyságrendileg csökken, amellett, hogy több webes felületet is kapunk a klaszter későbbi menedzselésének elősegítésére. A Hadoop által biztosított alapréteget általában modulokkal látják el, amik a célterület igényeit igyekeznek kielégíteni. A legismertebbek a Hue, a Hive és az Impala. A HUE egy webes interfész, amely adatok feltöltését és lekérdezések létrehozását teszi lehetővé. Az Impala egy lekérdező motor. A Hive felhasználási spektruma a legszélesebb, ugyanis ez egy komplex adattárház alkalmazás. Fentieken kívül a talán legfontosabbnak mondható elem a YARN. Ez a Hadoop jelenleg használatban lévő 2-es verziójának beépített erőforrás kezelője, elosztója. A YARN-ot tekinthetjük egy különálló operációs rendszernek is elosztott rendszerek számára, Big data kezelő, elemző alkalmazások számára. A YARN a MapReduce eljárás egy újraírása, annak refaktorizációja. A korábbi verzióban még Hadoop alapkomponensként szerepelt, mostanra azonban feladatkörének tágításával különálló alprojektként fejlesztik. A rendszer a futtatott job-okról széles körű információkat nyújt.
A rendszer helyes beállításához számtalan Tuning Spreadsheet elérhető, amelyek a rendelkezésre álló szabad erőforrásaink megadása után kiszámolják a konfigurációban beállítandó memória értékeket. A használat közben szerzett tapasztalatok alapján a Hadoop a fentieknél jóval kisebb erőforrásokon is képes működni, akár egy 2 node-os klaszteren is. 
